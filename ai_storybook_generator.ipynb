{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbc35af",
   "metadata": {},
   "source": [
    "# AI-Driven Custom Storybook Creation using LLaMA 13B & Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eedd796",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates how to create a personalized story generation system using the LLaMA 13B model and Streamlit. The system generates stories based on user inputs such as genre, themes, and characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb49dc",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Libraries\n",
    "We need to install `transformers` for loading the LLaMA model, `torch` for computations, `streamlit` for the UI, and `rouge_score` for evaluating the generated stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers streamlit rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84edff",
   "metadata": {},
   "source": [
    "## Step 2: Load the LLaMA 13B Model\n",
    "We use the Hugging Face `transformers` library to load the LLaMA 13B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e181d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"meta-llama/Llama-2-13b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "def generate_story(prompt, max_length=500):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output = model.generate(**inputs, max_length=max_length)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6181f4",
   "metadata": {},
   "source": [
    "## Step 3: Create a Streamlit UI for Story Generation\n",
    "We will create a simple UI where users can input their preferences, and the model will generate a story based on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1311ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"AI-Driven Custom Storybook Generator\")\n",
    "\n",
    "# User Inputs\n",
    "genre = st.selectbox(\"Select Genre\", [\"Fantasy\", \"Sci-Fi\", \"Mystery\", \"Adventure\"])\n",
    "theme = st.text_input(\"Enter a Theme\")\n",
    "characters = st.text_area(\"Describe the Main Characters\")\n",
    "\n",
    "if st.button(\"Generate Story\"):\n",
    "    prompt = f\"Genre: {genre}\\nTheme: {theme}\\nCharacters: {characters}\\nStory:\"\n",
    "    story = generate_story(prompt)\n",
    "    st.write(story)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435dbf18",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Story Quality Using ROUGE Score\n",
    "We use the ROUGE metric to assess the modelâ€™s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38219ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def evaluate_story(generated_story, reference_story):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference_story, generated_story)\n",
    "    return scores\n",
    "\n",
    "# Example usage (for testing purposes)\n",
    "reference_story = \"Once upon a time, in a magical forest, there lived a brave knight.\"\n",
    "generated_story = \"A long time ago, in an enchanted forest, a courageous knight set out on a journey.\"\n",
    "rouge_scores = evaluate_story(generated_story, reference_story)\n",
    "print(rouge_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7979e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook demonstrates how to build an AI-driven custom storybook generator using LLaMA 13B, Streamlit, and NLP techniques. The interactive UI allows users to input preferences and generate personalized stories, while the ROUGE score provides an evaluation metric for summarization quality."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
